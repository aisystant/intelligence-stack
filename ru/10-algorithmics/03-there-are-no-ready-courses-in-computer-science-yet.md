---
title: Готовых курсов информатики пока нет
---

Вот этот акцент в информатике на моделирование мира --- он важен. Текст
«Алгоритмика, информатика, моделирование, далее
везде»^[<https://ailev.livejournal.com/1265432.html>,
Этот подход продолжает реализовываться, см. доклад Кушниренко и Райко
«Дошкольная информатика без компьютера» (видео второго доклада
<https://vimeo.com/337031069>, слайды
<http://g-l-memorial.ice.ru/files/941738/Kushnirenko_Raiko_2019.pptm>).] ---
про обучение алгоритмике детишек на примере четырёх роботов
(«платоновский» робот, робот-из-программы, физический робот-на-коврике,
робот-из-возможного мира где-то в космосе). И первое же, что надо
уяснить  --- это соотношение между всеми этими роботами. С одной
стороны, это онтологическая задача (какие между этими роботами
отношения), с другой стороны  --- все эти роботы представляют собой
вычислители и описания вычислителей, надо понимать, как они связаны.
Сначала надо понимать, что такое «вычисление», а потом уже говорить об
этих вычислениях. Вычисление  --- это изменение состояний какой-то
памяти (то есть перевод мира из одного стабильного состояния в другое)
по какому-то алгоритму как набору операций с отдельными элементами
памяти. Запись алгоритма тоже может быть в памяти, как той же самой
(архитектура фон Неймана), так и отдельной (Гарвардская архитектура),
так и может быть распределена в какой-то нейросетевой структуре памяти.

Главное в информатике в целом и алгоритмике как её части --- это не
терять понимания, что именно моделируют те модели, с которыми ведутся
вычисления/рассуждения/вывод/исполнение. И помнить, что модель тоже
всегда исполняется: или модель исполняется на компьютере (имитационная
модель), или её исполняет рассматривающий глазами эту модель человек
(например, модель может быть дана в виде диаграммы в диаграммном
моделере, или таблички в каком-то универсальном моделере типа сoda.io,
или даже таблички в Excel, или даже в виде просто текста в MS Word как
моделере). Но всегда есть исполнение модели, без физического
вычислителя, «оживляющего» модель, она будет мертва. Такое понимание
нужно закладывать ещё в школьный курс информатики, а уж в образовании
для образованных и подавно.

В вузовские курсы информатики эта постановка задачи не попала, но уже с
этим начинаются какие-то подвижки в связи с распространением языковых
моделей типа ChatGPT, Claude, Bard, а также с пониманием, что:

-   Программирование таких нейросетевых вычислителей ведётся на
    естественном языке (мы уже упоминали прогноз Andrej Karpathy о том,
    что переход на программирование на естественном языке даст 1.6
    миллиарда программистов на планете)
-   Алгоритмика как создание эффективных алгоритмов, оторванных от
    предметной области (например, алгоритмы сортировки какой-то
    последовательности чисел по возрастанию или строк в алфавитном
    порядке) уходит от учёных к компьютерам. Свежий пример  --- это
    нахождение новых эффективных (для коротких последовательностей  ---
    эффективней на 70% по сравнению с известными до сих пор) алгоритмов
    сортировки программой AlphaDev от Google
    DeepMind^[<https://www.deepmind.com/blog/alphadev-discovers-faster-sorting-algorithms>].

Вместо универсального мышления про информатику как **алгоритмику**
** ---** **трансдисциплину о вычислителях и паттернах вычислений
(алгоритмов)**, на самых разных вузовских и вневузовских курсах учат
разрознённому набору «программирований» на разных языках
программирования, очень частным инженерным прикладным практикам.

Доходит до курьёзов, когда один из лучших в мире курсов по развитию
вычислительного мышления SIPC^[SICP (Structure and
Interpretation of Computer Programs вышел в 1979 году, 41 год назад), он
был «фундаментальным курсом» для computer science
(https://mitpress.mit.edu/sites/default/files/sicp/index.html).]
пришлось убрать из вузовской программы ещё в 1997 году. В основе курса
SIPC лежала функциональная парадигма, как очень удобная для размышлений
о вычислениях. Самая популярная сегодня парадигма в программной
инженерии --- объект-ориентированное программирование. Поэтому курс SIPC
нельзя непосредственно положить в основу сегодняшних курсов
программирования, он совсем не экономит время в обучении
инженеров-программистов, даже с учётом того, что все годы с момента
прекращения преподавания SIPC в программной инженерии неуклонно росла
доля людей, поддерживающих функциональный стиль программирования! Зато
курс SICP отлично справляется с развитием мозга изучающих его людей,
оставаясь удивительно непрактичным в части обучения текущей версии
программирования-как-ремесла. Критика SICP от 2005
года^[In short, SICP, Scheme, and functional programming
don't prepare students properly for other programming courses and thus
fail to meet a basic need ---
<https://www2.ccs.neu.edu/racket/pubs/jfp2004-fffk.pdf>. Название этой
критики SICP ровно то, что нам нужно --- The Structure and
Interpretation of the Computer Science Curriculum (Matthias Felleisen,
Northeastern University, Boston, MA, USA, Robert Bruce Findler,
University of Chicago, Chicago, IL, USA, Matthew Flatt, University of
Utah, Salt Lake City, UT, USA, Shriram Krishnamurthi, Brown University,
Providence, RI, USA).] подчёркивала важность отражения в
учебных курсах распространения объект-ориентированного программирования,
но в последние несколько лет жизнь ещё раз поменялась, и нужно учитывать
вот эти новые «программирования» --- вероятностное, дифференцируемое и
всё прочее, что приходит с коннекционистской парадигмой, все эти
Software 2.0 (код пишет алгоритм) и даже 3.0 (код пишется на
естественном языке как языке программирования, то есть «код» вообще не
пишется!). Вот «история алгоритмики» как история смены подходов к
программированию вычислений (то есть подходов к составлению алгоритмов
обработки каких-то данных):

**Софт/software** **1.0:**

-   Основано на программировании, основанном на формальных правилах
    выполнения формально определённых операций над формально
    определёнными данными.
-   Программы создаются путем явного кодирования правил и инструкций.
-   Ограниченная способность обучаться на основе данных или
    адаптироваться к новым ситуациям (ограниченная вменяемость: если
    хочется, чтобы программа могла как-то разбираться с новыми данными,
    надо её менять «вручную»).

**Софт/software**
**2.0:**^[<https://karpathy.medium.com/software-2-0-a64152b37c35>]:

-   Основано на искусственных нейронных сетях и глубоком обучении.
-   Программы
    дифференцируемы^[<https://ailev.livejournal.com/1464563.html>],
    поэтому способны обучаться на основе данных (обычно большой объём
    данных) и адаптироваться к новым ситуациям.

**Софт/software**
**3.0:**^[<https://divgarg.substack.com/p/software-3>]:

-   Основано на предварительном обучении больших языковых моделей/large
    language models (LLM). Обычно эти модели предобучаются/pretrained
    сначала на примерах программного кода, затем на больших массивах
    данных естественного языка и даже мультимедиа, и только потом их
    используют для программирования.
-   Эти большие языковые модели способны понимать естественный язык, а
    также понимать программный код на языке программирования или
    моделирования, они могут обучаться на небольших объёмах данных. В
    пределе  --- это программирующий/планирующий интеллектуальный агент
    с высокой вменяемостью.
-   Используется нейролингвистическое программирование (сегодня
    называется prompt engineering), то есть программирование нейросети
    на какое-то вычисление или на создание кода на языке
    программирования, каковой код будет потом выполнен на каком-то
    внешнем компьютере (классическом, квантовом или ином), ведётся на
    естественном языке.
-   Два варианта: или получается выполняемая программа как в Software
    2.0 (часть нейросети просто аппроксимирует нужную функцию), или
    получается выполняемая программа как в Software 1.0 (и тогда
    нейросеть способна объяснять получившуюся программу, а также
    оптимизировать её  --- синтезировать более эффективные алгоритмы,
    чем придумываемые людьми).

Базовый курс информатики опять должен поменяться, и при этом мы даже не
говорим о квантовых или оптических компьютерах, робототехнике, не
говорим о биологических компьютерах на искусственно выращенных
органоидах, например, искусственно выращенных мозгах людей или мышей,
которые тоже рассматриваются как перспективные
устройства-вычислители/компьютеры (все они оказываются энергетически
весьма
выгодны^[<https://www.frontiersin.org/journals/science/articles/10.3389/fsci.2023.1017235>]).
В любом случае, на данный момент нет какого-то консенсуса на тему
содержания дисциплины информатики и алгоритмики как связанной с
эффективностью вычислений части информатики как общей трансдисциплины
моделирования. Почему моделирование? Потому что один физический объект
«компьютер с моделью» является моделью другого физического
«моделируемого объекта», возможно, по длинной «цепочке моделирования».

Трансдисциплина алгоритмики нужна не только для программных
инженеров/software engineers или «учёных по данным»/data scientists. Мы
можем говорить об условном директоре стадиона: он имеет на своём
попечении робота, который внутрь себя забирает 5 тысяч человек и два
часа развлекает, а потом отдаёт этих 5 тысяч человек назад в окружение.
У этого робота-стадиона есть вычислительные ресурсы, есть датчики и
актуаторы, частью этого робота являются и его сотрудники. Знание какой
трансдисциплины научит людей думать про свои предприятия таким образом?
Это знание научит миллиарды людей разговаривать с «айтишниками» --- не
работать вместо них, а обсуждать их работу в условиях неминуемого
разделения труда и неминуемой автоматизации этого труда. А кто тут будут
эти «айтишники»? По факту это будут и другие люди (почти все, поскольку
моделируют и вычисляют что-то по этим моделям все  --- как с
использованием собственного мозга как вычислителя, так и с
использованием экзокортекса с внешней памятью или даже внешним
вычислителем). Более того, общаться надо будет с AI, который тем самым
будет «свой айтишник» («сделай мне программу, которая будет давать мне
сигнал на телефон, если в чат напишет Вася или его бот, а остальные
оповещения будет откладывать для просмотра их в более удобное время»
 --- это вы скоро будете голосом прямо говорить своему смартфону, и он
поймёт! Сейчас такое пишут программисты, завтра такое пишут сами
компьютеры).

Люди в своей массе должны знать, что как человеческий, так и машинный
интеллект  --- это не результат работы алгебраических торсионных полей и
не трансляция сигналов Космоса.

Современный человек должен понимать, где границы возможного. Человек в
18 веке должен был знать, что полёты на ковре-самолёте --- чудеса.
Человек в 21 веке должен знать, что полёты на Марс --- не чудеса, и что
полностью повторно используемые ракеты --- не миф. Может ли сегодня
человек отличить реферат текста, сделанный компьютером от реферата
текста, сделанного человеком? Это ведь трудная задача, над ней бились
безуспешно десятки лет? Объяснялось, что для такого нужно иметь огромную
эрудицию, которую может иметь только человек. Но нет, с 2020 года
рефераты текстов, сделанные компьютерами и людьми, неотличимы друг от
друга самими
людьми^[<https://ai.googleblog.com/2020/06/pegasus-state-of-art-model-for.html>].
Граница того, что могут сделать только люди, что могут и люди, и
алгоритмы машинного интеллекта, а что уже не могут люди, но могут
алгоритмы машинного интеллекта  --- она непрерывно сдвигается в пользу
машинного интеллекта.

Курс алгоритмики посвящён обучению тому, что всё это не магия, а обычная
инженерная работа. **Булки растут не на деревьях, мышление растёт
необязательно в мозге, современный человек должен это понимать, иначе
все его стратегирования будут фантазиями, основанными на магическом
понимании технической реальности.**
