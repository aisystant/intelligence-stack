---
title: 'Пример: физмат-моделирование сознания и эволюции'
---

Если «глазами по формулам» работать с теорией информации, разбираясь с
«похожестью» формул, как это делал Shannon, то по аналогии с
термодинамикой можно ввести и энтропию (информационную!), и свободную
энергию (информационную!). E.T.Jaynes в «Теории вероятности как логике
науки»^[<https://disk.yandex.ru/i/xOMTIe0drCE1tw>]
просил не путать термодинамику и информатику, но далее оказалось вполне
продуктивным таки их путать. Например: появляются тексты, где строится
вполне строгая теория квантовых безмасштабных описаний физического
выражения информационных явлений: Chris Fields со товарищи в 2020 году
пишет работу «Information flow in context-dependent hierarchical
Bayesian
inference»^[<https://chrisfieldsresearch.com/contextual-pre.pdf>]:
«Последние теории, развивающие широкие представления о контексте и его
влиянии на умозаключения, становятся все более важными в таких разных
областях, как когнитивная психология, информатика и квантовая теория
информации и вычислений. Здесь мы представляем новый и общий подход к
характеристике контекстуальности, используя методы пространств Чу и
теории каналов, рассматриваемых как общие теории информационных потоков.
Это предполагает введение в формализм трех существенных компонентов:
событий, условий и систем измерения».

Пространства
Чу^[<https://en.wikipedia.org/wiki/Chu_space>] ---
это обобщение топологического пространства и там хорошо строить
отображения разнородных объектов друг в друга. Например
«типы-как-процессы»/types-as-processes, обновляющие понимание
данных-как-программ/data-as-programs. В тексте «Types as Processes, via
Chu
spaces»^[<https://www.sciencedirect.com/science/article/pii/S157106610580475X/pdf?md5=baf9bdce177de225c314936d190bca59&pid=1-s2.0-S157106610580475X-main.pdf>],
1997, говорится: «Типы-как-процессы вводятся как соответствие
Карри-Ховарда \"пропозиции-как-типы\"/propositions-as-types, в котором
пропозиции заменены процессами. Поскольку типы и процессы являются
частью рабочего инструментария программиста, даже в большей степени, чем
пропозиции, соответствие типы-как-процессы является более центральным
для практики программирования, чем пропозиции-как-типы. Более того, эта
связь очень хорошо работает математически, по крайней мере, до
определённого момента».

И дальше по этой линии обобщения самой разной математики при помощи
теории категорий с пространствами Чу на «естественную математику»,
Rational Mechanics and Natural
Mathematics^[<https://www.newdualism.org/papers/V.Pratt/ratmech.pdf>],
2005: «Пространства Чу нашли применение в информатике, математике и
физике. Они обладают полезной категориальной двойственностью,
аналогичной теории решёток и проективной геометрии. Как естественная
математика пространства Чу заимствуют идеи из естественных наук, в
частности, из физики, а как рациональная механика - из гамильтоновой
механики в терминах взаимодействия тела и разума».

Развитие этой линии рассуждений приводит к тексту «Minimal physicalism
as a scale-free substrate for cognition and
consciousness»^[<https://chrisfieldsresearch.com/min-phys-NC-2021.pdf>],
2021, от Chris Fields, James F. Glazebrook and Michael Levin, с опорой
на уже упоминавшуюся
ITT^[<https://en.wikipedia.org/wiki/Integrated_information_theory>]
как физикалистскую теорию сознания, а далее «A free energy principle for
generic quantum
systems»^[<https://arxiv.org/abs/2112.15242>],
2021, от Chris Fields, Karl Friston, James F. Glazebrook, Michael
Levin, --- продолжение темы мышления и сознания с безмасштабным
квантовоподобным описанием, но с добавкой идей active inference. И в
этом направлении математизации теории сознания (математизация --- это
получение достаточной строгости/формальности описаний, чтобы можно было
«измерить и посчитать», то есть переход от философии к физике
посредством добавки математики в её онтологической функции) были даже
работы^[<https://philpapers.org/archive/FRITAC-4.pdf>],
где теории сознания проверяются на колониях муравьёв, и там прямо
адресуется проблема «биологического индивида» и понятие сознания для
сообществ. Хотя в этой работе ещё нет ничего квантового и
безмасштабного, это только 2019 год, но это уже с опорой на IIT.

Эти же Chu spaces используются и дальше с прицелом на математику для
онтологии, как foundational ontology (в отличие от логик первого
порядка, которые традиционны в современной computational ontology для
использования в качестве foundational ontology). Например, работа
«Distributed Conceptual
Structures»^[<https://arxiv.org/abs/1810.04774>],
2018: «Теория распределенных концептуальных структур, изложенная в
данной работе, занимается распределением и формированием знаний. Она
опирается на две родственные теории, информационного
потока^[<https://en.wikipedia.org/wiki/Information_flow_(information_theory>)]
и формального анализа
понятий^[<https://en.wikipedia.org/wiki/Formal_concept_analysis>],
которые она стремится объединить. Информационный поток (ИП) связан с
распространением знаний. Основы информационного потока явно базируются
на математической теории, известной как конструкция
Чу^[<https://ncatlab.org/nlab/show/Chu+construction>]
в \*-автономных категориях, а неявно - на математике замкнутых
категорий. Формальный анализ понятий (FCA, formal concept analysis)
занимается формированием и анализом знаний. В данной работе мы связываем
эти два исследования, распространяя основную теорему формального анализа
понятий на распределённую область информационных потоков. Основными
результатами являются категориальная эквивалентность между
классификациями и решётками понятий на уровне функций и категориальная
эквивалентность между связями и полными примыканиями на уровне
отношений. Этим мы надеемся достичь сближения между информационным
потоком и формальным анализом понятий».

Другой ход по линии теорий сознания --- это уже упомянутую ITT с её
панпсихизмом физикалистского толка («сознание --- это свойство
физического мира во всём диапазоне от неживого до живого, включая
организмы и даже сообщества организмов») смешивают с также
ориентированной на математику и «посчитать» теорией сознания global
workspace^[<https://en.wikipedia.org/wiki/Global_workspace_theory>]
и получают integrated world modeling
theory/IWMT^[<https://psyarxiv.com/kjngh/>].
В этой IWMT нет пространств Чу и теории категорий, но мы видим всё тот
же набор идей по использованию математики как онтологии в области
сложных феноменов, включая даже модные VAE
GAN^[<https://en.wikipedia.org/wiki/Variational_autoencoder>,
<https://en.wikipedia.org/wiki/Generative_adversarial_network>]
(порождающие нейронные сети на базе вариационных автоэнкодеров ---
помним, что нейронные сети тоже являются мощнейшей унификационной
парадигмой в силу их доказанной универсальности как аппроксиматоров
любых функций).

И таких работ «математизации» или «физикализма» (это две стороны одной
медали) для ранее считавшихся «философскими» областей знания о сознании
становится всё больше и больше. Мы видим, что прямо на глазах
философское бла-бла-бла (которое не кончается ничем, экспериментами не
проверишь, не «посчитаешь») в теориях сознания потихоньку переходит в
естественную науку, онтология которой берётся из математики --- из тех
её областей, которые обладают наибольшим унификационным потенциалом.

Идеи информационной вселенной, где вещество во вселенной ведёт обработку
информации как в тупой форме «камня», так и в форме простых и сложных
жизненных форм и даже социальных форм той же жизни (человечество тут как
пример) --- это очень модная идея. Например, так считает квантовый физик
Виталий Ванчурин в его ключевой работе на эту тему с выводом о вселенной
как работающей непрерывно обучающейся/познающей
нейросети^[<https://iopscience.iop.org/article/10.1088/2632-2153/abe6d7/meta>].
Основная идея современной физики --- это то, что под уровнем квантовой
механики, описывающей поведение квантового мира частиц, из которых
сделаны атомы, хорошо математически выражаемым постулатами квантовой
теории поля^[<https://disk.yandex.ru/d/WbIxH66UCgQfRw>,
<https://en.wikipedia.org/wiki/Quantum_field_theory>]
лежит ещё один уровень математических структур, который потом можно
будет использовать для объектов всё более и более крупного размера ---
но вот вести себя даже для уровня квантовых частиц эти ментальные
структуры будут так, что их поведение выглядеть будет похоже на
поведение квантовых полей. Есть множество вариантов таких «более мелких»
структур, которые начинают вести себя как квантовые поля, но на самом
деле не являются квантовыми полями: теория
струн^[<https://en.wikipedia.org/wiki/String_theory>]
тут самая известная, Stephen Wolfram предлагает различные
графы^[<https://www.wolframphysics.org/>],
David Deutsch предлагает
ссоздателей/constructors^[<http://constructortheory.org/>],
Виталий Ванчурин предлагает
нейроны^[<https://www.youtube.com/watch?v=RIEtRGfFSGI>,
<https://www.youtube.com/watch?v=p6mUVE6nmGY>] --- это
одна из основных мыслей его работ. Он говорит, что математика глубокого
обучения/deep
learning^[<https://en.wikipedia.org/wiki/Deep_learning>]
вполне подходит для описания
динамики^[<https://en.wikipedia.org/wiki/Analytical_dynamics>,
<https://en.wikipedia.org/wiki/Dynamics_(mechanics>)]
(описания изменений физического мира), и эволюция вселенной (в которую
входит и эволюция жизни, и техно-эволюция) --- это просто
познание/обучение/learning этой многоуровневой нейронной сети. То есть
мир состоит из нейронов, которые как-то взаимодействуют друг с другом, и
это надо рассматривать на многих уровнях (deep learning, многослойные
нейронные сети --- это как раз отсылка к уровням). И если идти по этому
пути «в основе всего лежат нейроны и обучение нейронных сетей», то у
Ванчурина даже есть идеи, как обобщить математику (а, если
математика --- это онтология, то и физику) до минимальной, в которой
остаётся свойство обучения --- а затем предложить физические устройства,
реализующие эту математику непосредственно. Ванчурин основал
компанию^[<https://artificialneuralcomputing.com/>],
которая даже будет пытаться выпускать такие устройства. И вот там-то
будут работать «нецифровые компьютеры», ибо привычные «цифровые
компьютеры» на цифровых логических цепях очень неэффективны для
глубокого обучения. Показательна строчка копирайта с сайта компании
Виталия Ванчурина: «Copyright © 2023 Artificial Neural Computing Corp.-
All Rights Reserved by the Universe. Temporarily powered by digital
computers».

Везде в этих проектах проводится одно и то же рассуждение: берём
какие-то математические/ментальные объекты --- и объявляем их поведение
похожим на поведение базовых физических объектов, из которых устроена
реальность. Дальше могут быть два варианта:

-   философы и математики пишут статьи, и на этом дело заканчивается ---
    никакой физики, экспериментов, «измерить и посчитать».
-   физики придумывают эксперименты, в которых можно вычислить
    наблюдаемые свойства реальности на базе вот этой математики --- и
    тем самым проверить, верна ли догадка.

Скажем, есть такие математические объекты как поля, частицы, струны,
нейроны. Дальше можно учесть, что поля очень удобны для описаний
происходящего в мире, если считать, что в физическом мире есть такие
физические «поля», которые ведут себя в чём-то похоже на то, как ведут
себя математические «поля». Но такое поведение наблюдается не везде и не
всегда (особенно при смене масштабов --- размеров, времени, энергий),
проблемы в описании мира остаются. Тогда можно взять более мелкие
объекты (струны или нейроны, или ещё какие) --- и сказать, что на
каком-то масштабе эти струны или нейроны ведут себя вполне как поля. Но
это надо показать математически (формулы!) и проверить в эксперименте
(измерения!), «посчитать» (смоделировать реальность --- и проверить,
совпадает ли результат моделирования с экспериментом лучше, чем у
альтернативных теорий).

Если считать, что эти идеи обучения будут безмасштабными, то можно
ставить эксперименты, например Ванчурин выдвигает идею «биологического
коллайдера»: берём две биологические системы в равновесии, «познавшие
мир» и сталкиваем их друг с другом в борьбе за выживание --- и дальше
смотрим, можем ли мы это описать нашими формулами. Та же идея, что с
элементарными частицами и ускорителями: столкнуть и тем самым поломать,
чтобы поглядеть, как оно там устроено.

Можно проверять математику и другими методами, например, математика
подхода active inference говорит, что любая достаточно сложная система
(например, нейроны мозга мыши или человека, которые были выращены на
пластине) будет уменьшать неопределённость в окружении. В эксперименте
DishBrain^[<https://www.cell.com/neuron/fulltext/S0896-6273(22)00806-6>]
проверили ровно это: вырастили нейроны на электронной подложке и
погрузили их в мир игры Pong. И за пять минут нейросеть научилась играть
в Pong, безо всякого знания о «наградах»: наградой было то, что на входы
системы не подавали шум, не увеличивали неопределённость, а вот в случае
промаха ракеткой по мячику на вход подавали некоторое количество шума,
увеличивали неопределённость окружающей среды --- и через пять минут
нейроны научились управлять окружающей средой так, чтобы снизить
неопределённость, то есть перестали промахиваться виртуальной ракеткой
по виртуальному мячику!

Тип этого эксперимента DishBrain ровно такой же, как открытие «на
кончике пера» планеты
Нептун^[[https://ru.wikipedia.org/wiki/Открытие\_Нептуна](https://ru.wikipedia.org/wiki/Открытие_Нептуна)],
а также создание атомной бомбы на основе выводов теории относительности
(«принятие всерьёз», то есть принятие как основание для действий в
физическом мире математических выкладок, описано в книгах David Deutsch)
или создание квантовых компьютеров на основе математических описаний
того же David Deutsch. И вот уже появляется работа по созданию
биологических
компьютеров^[<https://www.frontiersin.org/journals/science/articles/10.3389/fsci.2023.1017235>],
выход этой математики в физический мир по линии organoid intelligence
(organoid^[<https://en.wikipedia.org/wiki/Organoid>] ---
это выращенная «в пробирке» биологическая ткань какого-то органа,
например, культура нейронов млекопитающих) и тоже создание
компании^[<https://corticallabs.com/>],
которая на основе этих математических (вернее, физико-математических)
идей собирается строить органоидные компьютеры.

Тут нужно удерживать во внимании это постоянное различение: как сделали
бы философы (написали статью про нарезку мира на какие-то объекты --- и
что дальше? дальше ничего!), как сделали бы математики («вот забавные
свойства вот таких ментальных объектов» --- и что дальше? Что с этим
делать?) и как делают физики (взять математику, проверить экспериментом,
выдать физический эффект для инженеров, которые ищут очередной
аффорданс).

Ванчурин подчёркивает, что в идее «нейрон как основа физической теории»
лежит не квантовая механика, не классическая механика, а «другая
математика, математика обучения». Смена онтологии (идей о том, из каких
объектов составлен окружающий мир) сводится к смене математики, а дальше
двустороннее движение --- надо от этой математики прийти к описанию в
терминах полей как «смене масштаба», потому что эти описания хорошо
работают, но и наоборот --- эксперименты с полями должны как-то
валидировать математику познания/обучения/learning на основе нейронов. И
там получается много интересного на этом пути «другой математики в той
же физике»: скорость света познаётся/выучивается/learn, антропный
принцип^[<https://en.wikipedia.org/wiki/Anthropic_principle>]
(константы удобны для жизни в целом и для существования людей в
частности) становится другим --- «удобные константы
познаются/выучиваются, то есть природа к этой физике как набору
постоянных/физических констант, удобных для существования разных
устойчивых объектов, в том числе и людей, эволюционирует». И даже
пространство-время становится не базовым, а эмерджентным/emergent
(появляющимся на более высоких системных уровнях) понятием и
соответствующим этому понятию объектом.

В работе «Ontological revision and quantum
mechanics»^[<https://www.sciencedirect.com/science/article/pii/S2211379721011165>],
2022, говорится о том, что или вы берёте какие-то феномены и начинаете
искать математику для выражения этих феноменов, или наоборот --- если
есть удобная математика, то нужно попросту переопределить онтологию
физических объектов, используя эту математику. Скажем, не «частицы» или
«волны», а какие-то другие описания материи. В этой работе говорится,
что понятие «состояние» понимается как склонность объекта вызывать
события у наблюдателей. Дальше работа предлагает онтологически
объединить пространства положения и импульса в единое целое, связанное
через преобразование Фурье --- это же привычно для физики, точно так же
ввели пространство-время, и такой ход Эйнштейна не вызвал какого-то
особого отторжения у физиков. На основе этой пересмотренной онтологии
квантовая механика выводится естественным путем, не опираясь на
какие-либо искусственные предположения, такие как «квантовое условие»
(по поводу которых до сих пор идут онтологические
споры^[<https://onlinelibrary.wiley.com/doi/full/10.1002/qute.202100158>]),
или математические аппараты, такие как гильбертово
пространство^[[https://ru.wikipedia.org/wiki/Гильбертово\_пространство](https://ru.wikipedia.org/wiki/Гильбертово_пространство)]
и самосопряженные
операторы^[[https://ru.wikipedia.org/wiki/Эрмитов\_оператор](https://ru.wikipedia.org/wiki/Эрмитов_оператор)].
Как следствие, такие острые вопросы, как «проблема
измерения»^[<https://en.wikipedia.org/wiki/Measurement_problem>],
либо разрешаются, либо просто исчезают.

Cамая интересная часть работы «Ontological revision and quantum
mechanics» --- это попытки рассуждать про онтологию и теорию познания
(рациональность и исследования, то есть эпистемологию) в физике, и как
находить в одних и тех же математических (если с размерностью --- то
физических) формулах самое разное понимание. Нет впечатления, что эта
работа будет каким-то мейнстримом: на любую новую фундаментальную идею в
математике и физике нужно много-много «вязания на спицах»: показывать
феномен за феноменом, что каждый из этих феноменов переописывается
проще, чем с использованием текущей физики (набор объектов физического
мира с их свойствами) и математики (какие математические объекты были
выбраны для моделирования физических объектов), или выглядят точнее в
новой математике и физике. Без этого никакого широкого распространения
теория не получит, но ресурсов на такую обширную работу ни у кого нет.

Тот же David Deutsch не слишком продвигается с constructor theory, ибо
недостаточное число людей готовы овладеть новым набором базовых понятий,
у Ванчурина и его команды амбиции по нейронной теории вселенной
большие --- но он и сам признаёт, что вот эта часть проверок и
демонстрации того, что описание мира становится проще и объясняет мир
точнее, ещё впереди, и непонятно, кто даст на это ресурсы.

При таком подходе можно брать за основу описания мира самые разные
ментальные объекты. Например, если смотреть на работы Hwe Ik Zhang
(автора статьи про ontological revision и quantum mechanics), то можно
найти там и работы по математике и физике, стоящими за классическим
восточным подходом Инь-Ян
И-Цзин^[<https://en.wikipedia.org/wiki/I_Ching>],
это очень популярная тема на Востоке: если можно класть какую-то
онтологию в основании бытия и подтверждать её потом математикой-физикой,
типа тех же «струн» или «нейронов», то что б не взять сразу привычный
И-Цзин и понятия противоположностей Инь-Ян?! По этой линии
предлагается^[<https://www.sciencedirect.com/science/article/pii/S2213422020300949>]
современная переформулировка И-Цзин для биологии. Все эти попытки
упираются в то, что какая-то такая «догадка об интересных (то есть с
самым разным нетривиальным поведением) ментальных объектах и математике,
стоящей за ними (то есть строго описанное, хорошо понятное поведение)»
должна привести к смене онтологии/ontology revision --- и надо вот
просто взять, и всё остальное переписать с опорой на эту догадку, каждый
раз показывая, что при переписке не теряется связь с экспериментом, что
точность предсказаний мира не ухудшается. Но ресурсов на такое ни у кого
нет. Почему у Ньютона и Лейбница получилось, почему у Шрёдингера
получилось, почему у Эйнштейна получилось --- не очень понятно, это
очень интересный вопрос.

Даже если убрать связь математики и физики, в самой математике тоже
радикальные идеи часто не имеют шансов. Например, классический случай
Синити
Мочизуки^[<http://en.wikipedia.org/wiki/Shinichi_Mochizuki>],
который попытался радикально преодолеть один из барьеров сложности в
математике, но не
преуспел^[<https://www.svoboda.org/a/26921920.html>] ---
слишком мало математиков поняли его идеи. Профессиональному математику
понять какую-то новую теорию в математике --- это затратить на 1500-2500
страниц 250-500 часов труда, по 5-6 страниц абсолютно нового сложного (с
незнакомыми формулами и идеями!) материала в час. Для физиков это будет
примерно то же самое, но всё может оказаться сложнее, ибо в физике ещё
есть место эксперименту, и с экспериментами тоже надо разобраться,
просто «прочесть» не получится. Это означает, что кто-то из авторов
теории пишет начальных 1500-2500 страниц изложения картины мира на базе
каких-то новых радикальных понятий, а дальше любому новому человеку надо
потратить 250-500 часов труда, чтобы продолжить развивать теорию,
переписывать на этот новый язык все новые и новые описания, которые и
так уже описаны старой теорией. Барьер оказывается ресурсный! Более
того, в ходе такого переписывания не факт, что всё окажется лучше:
возможно, будут найдены какие-то непреодолимые затруднения, и всё
окажется зря, победит в конечном итоге другая идея. А ещё для первых
последователей не будет кому проверить их выкладки (в том числе
проверить выкладки самого первого автора). Поэтому есть огромные надежды
на применение искусственного интеллекта, который сможет работать с
такими радикальными идеями: во-первых, порождать такие идеи (типа
объединения пространства и времени в пространство-время или объединить
положение и импульс в один объект, или представить весь мир как нейроны
или струны), а затем пробовать «переписать всю физику, уж сколько можно»
на этот новый математический аппарат, подразумевающий выражение новых
физических объектов. Но даже для искусственных интеллектов это может
быть крайне трудно по ресурсам: представьте себе, что речь идёт о
перетолковывании миллионов научных статей!

Но такие радикальные ходы в науке могут быть очень продуктивны, поэтому
есть вероятность, что люди будут вкладываться, если демонстрировать
универсальность предлагаемого подхода. Так, Ванчурин и его соавторы
демонстрируют стандартный ход «аналогии теорий, определяемых на базе
структуры математических формул» на смешивании рассуждений для
математически выраженных фреймворков термодинамики, теории эволюции и
теории нейронных сетей в работе «Thermodynamics of evolution and the
origin of
life»^[<https://www.pnas.org/doi/full/10.1073/pnas.2120042119>],
см. там, например, \[7.6\] и \[7.7\] про отношения между физическими и
биологическими величинами. Это общий ход в рассуждениях такого сорта:
«если математика одна и та же, то это проявление общего физического
принципа, паттерн поведения вселенной». Так, free energy в
информационной теории Шеннона сначала имела смысл не «физической
энергии», а совсем другой смысл, просто «в формулах на этом месте в
физике стоит обычно энергия, поэтому мы сохранили название в
информатике». Но затем жизнь поменялась, и понятие «энергия» в физике
стало обозначать ровно вот это --- «какой-то физический объект, который
ведёт себя так, как ведёт величина из формул, где участвует
ментальный/математический объект «энергия»».

Заканчивается вся эта линия рассуждений Ванчунина и соавторов про
нейроны и математику обучения как основы физики теорией многоуровневой
эволюции как оптимизационного вычисления-познания по типу нейронной
сети, «Towards a Theory of Evolution as Multilevel
Learning»^[<https://arxiv.org/abs/2110.14602>],
2021.
